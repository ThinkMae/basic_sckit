{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sckit-learn_5models.ipynb","provenance":[],"authorship_tag":"ABX9TyNjzzAbzMLdd7kIWg4B89qh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"KKL8oOgL5mxR"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qbCIxkNs6T8M"},"source":["# Mini prj 02 : Trainning 5 models and evaluation\n","author : bae hueng myoung\n","date : 28 sep 2021\n","prj goals : \n","    1) using scikit-learn\n","    2) 5 models trainning and evaluation\n","    3) assessment\n","\n","\n","# required modules\n","\n","from sklearn.datasets import load_digits, load_wine, load_breast_cancer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn import svm\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.linear_model import LogisticRegression\n","\n","# data load\n","\n","# (1) data = handwriting\n","hand = load_digits()\n","print(dir(hand))\n","\n","hand_data = hand.data\n","hand_label = hand.target\n","\n","# (2) data = wine \n","wine = load_wine()\n","print(dir(wine))\n","\n","wine_data = wine.data\n","wine_label = wine.target\n","\n","# (3) data = breast\n","breast = load_breast_cancer()\n","print(dir(breast))\n","\n","breast_data = breast.data\n","breast_label = breast.target\n","\n","print(breast_data[0])\n","print(breast_data.shape)\n","print(type(breast_data))\n","print(wine.DESCR)\n","\n","# split train and test set\n","\n","import pandas as pd\n","hand_data_frame = pd.DataFrame(data = hand_data,columns=hand.feature_names)\n","hand_data_frame[\"label\"] = hand.target\n","print('hand dataframe : \\n',hand_data_frame)\n","\n","wine_data_frame = pd.DataFrame(data = wine_data,columns=wine.feature_names)\n","wine_data_frame[\"label\"] = wine.target\n","print('wine dataframe : \\n',wine_data_frame)\n","\n","breast_data_frame = pd.DataFrame(data = breast_data,columns=breast.feature_names)\n","breast_data_frame[\"label\"] = breast.target\n","print('breast dataframe : \\n',breast_data_frame)\n","\n","\n","\n","# split train and test data\n","hx_train,hx_test,hy_train,hy_test = train_test_split(hand_data,hand_label,test_size=0.2,random_state=7)\n","print('hand train num',len(hx_train), 'hand test num',len(hx_test))\n","\n","wx_train,wx_test,wy_train, wy_test = train_test_split(wine_data,wine_label,test_size=0.2,random_state=7)\n","print('wine train num',len(wx_train), 'wine test num',len(wx_test))\n","\n","bx_train,bx_test,by_train,by_test = train_test_split(breast_data,breast_label,test_size=0.2,random_state=7)\n","print('breast train num',len(bx_train), 'breast test num',len(bx_test))\n","\n","\n","# training and evaluation (5 models)\n","\n","from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n","\n","\n","def classifier_modle(x_train,x_test,y_train,y_test):\n","    \n","# (1) set ML 5 models(decsion tree, random forest, svm, sgd, logistic regression)\n","\n","    decision_tree = DecisionTreeClassifier(random_state=32)\n","    #print(decision_tree._estimator_type)\n","\n","    random_forest = RandomForestClassifier(random_state=32)\n","    #print(random_forest._estimator_type)\n","\n","    svm_model = svm.SVC()\n","    #print(svm_model._estimator_type)\n","\n","    sgd_model = SGDClassifier()\n","    #print(sgd_model._estimator_type)\n","\n","    log_model = LogisticRegression(solver='liblinear')\n","    #print(log_model._estimator_type)\n","\n","# (2) train and evaluation\n","    decision_tree.fit(x_train,y_train)\n","    dy_pred = decision_tree.predict(x_test)\n","    print('decision tree model : \\n',classification_report(y_test,dy_pred))\n","    print('accuracy : ',accuracy_score(y_test,dy_pred))\n","    \n","    random_forest.fit(x_train,y_train)\n","    ry_pred = random_forest.predict(x_test)\n","    print('random forest model : \\n',classification_report(y_test,ry_pred))\n","    print('accuracy : ',accuracy_score(y_test,ry_pred))\n","\n","    svm_model.fit(x_train,y_train)\n","    sy_pred = svm_model.predict(x_test)\n","    print('svm model : \\n',classification_report(y_test,sy_pred))\n","    print('accuracy : ',accuracy_score(y_test,sy_pred))\n","    \n","    sgd_model.fit(x_train,y_train)\n","    sgy_pred = sgd_model.predict(x_test)\n","    print('sgd model : \\n',classification_report(y_test,sgy_pred))\n","    print('accuracy : ',accuracy_score(y_test,sgy_pred))\n","\n","    log_model.fit(x_train,y_train)\n","    lgy_pred = log_model.predict(x_test)\n","    print('log model : \\n',classification_report(y_test,lgy_pred))\n","    print('accuracy : ',accuracy_score(y_test,lgy_pred))\n","\n","    \n","\n","# train models and evaluation\n","\n","print('#######data = handwriting#######')\n","classifier_modle(hx_train,hx_test,hy_train,hy_test) # data = handwriting\n","print('#######data = wine#######')\n","classifier_modle(wx_train,wx_test,wy_train,wy_test) # data = wine\n","print('#######data=breast#######')\n","classifier_modle(bx_train,bx_test,by_train,by_test) # data = breast\n","\n","# report prj : 3 type data classification and evaluation by 5 models\n","\n","overview : \n","    scikit-learn api는 다양한 모델들을 제공하고 유저가 유용하게 기계학습 모델을 이용하는 편의성을 제공하고 있다. 하지만 모델들은 서로 다른 특징들을 갖고 있으며 유저가 어떠한 모델을 사용하는 것이 가장 바람직한것인가에 대해서 선택하여야 한다. 이 프로젝트에서는 supervised learning에서 classification을 위한 기계학습에 필요한 여러 모델을 이용해보고 각 데이터 종류에 따라 가장 좋은 성능을 선택하는 기준을 마련하고자 한다.\n","    \n","    \n","data type :\n","이 프로젝트에서는 핸드라이팅, 와인, 유방암의 3가지 종류의 데이터를 선정하였다. 이 데이터들에 대해 분류라는 같은 목적을 가지지만 데이터의 속성들의 차이점을 지니고 있다. 이 속성들은 어떤 모델을 선택하느냐가 더 적절한지에 대해 중요한 변수로 작용할것 이다. 예를 들면 핸드라이팅의 데이터 클래시피케이션에서 가장 우수했던 모델이 속성이 다른 와인의 데이터의 클래시피케이션에서 가장 우수한 모델로 작용하지 않을 수 있다. \n","\n","\n","3가지 종류의 클래시피케이션 별 5개 모델의 성능 결과 : \n","\n","(hand)  \ttree\tRF\t    svm\t    sgd\t    logR\n","accuracy\t0.86\t0.96\t0.98\t0.93\t0.944\n","precision\t0.86\t0.96\t0.99\t0.96\t0.95\n","reccall \t0.86\t0.96\t0.99\t0.93\t0.95\n","f1_score\t0.86\t0.96\t0.99\t0.93\t0.94\n","\t\t\t\t\t\n","(wine)\t\ttree\tRF\t    svm\t    sgd\t    logR\t\t\t\n","accuracy    0.94\t1\t    0.61\t0.52\t0.97\n","precision   0.96\t1    \t0.59\t0.4\t    0.98\n","recall   \t0.94\t1   \t0.61\t0.53\t0.97\n","f1_score\t0.95\t1   \t0.56\t0.44\t0.97\n","\t\t\t\t\t\n","(breast)\ttree\tRF\t    svm\t    sgd\t    logR\t\t\t\n","accuracy\t0.91\t1\t    0.9\t    0.84\t0.94\n","precision\t0.91\t1   \t0.92\t0.87\t0.95\n","recall  \t0.91\t1   \t0.9\t    0.84\t0.95\n","f1_score\t0.91\t1   \t0.9\t    0.85\t0.95\n","   \n","\n","    어떤 데이터가 어떤 모델에 적합한지를 판단하는 기준은 정확도를 가장 우선으로 꼽았다. 그 이유는 노드에서 진행했듯 precision의 값으로는 성능을 평가하는데 적합하지 않기 때문이다. 여러 숫자 데이터 중 '3'과 그렇지 않은 숫자를 클래시피케이션을 하는 모델은 정밀도가 매우 우수하다. 하지만 3이 아닌 숫자를 3이 아니라는 false negative는 보장하지 못하는 한계를 갖는다. 따라서 모델의 성능 지표는 정밀도보다 정확도가 더 타당하였다. 이번 프로젝트에서도 정밀도보다 정확도에 성능 평가 기준에 무게를 두었다. 핸드라이팅의 경우 숫자들을 구분짓는 것은 데이터의 분포에 다라 정밀도는 유효할 수도 있고 의미가 없을 수 있다. 특히 유방암 진단에서 단순히 옳은 것을 찾아내는 정밀도는 매우 위험할 수 있다. 유방암과 같은 중한 질병을 진단할 때의 오진은 자칫 필요없는 큰 비용을 지불해야 할 수 있기 때문이다. 실제 유방암이 아닌 사람이 유방암이라고 잘못 진단했을 때는 단순히 손글씨의 분류와 전혀 다른 문제를 낳는다. 따라서 유방암 진단은 잘못 예측한 부분까지 모두 고려하여야하며 모든 경우의 수를 포함한 정확도(accuracy)가 모델의 성능을 평가하는데 적합하다고 판단하였다.\n","\n"," \n","which model is good? : \n","    위의 결과를 보면 각 데이터의 종류에 따라 모델들의 성능들이 달리 나옴을 알 수 있었다. 손글씨를 학습해 본 결과 가장 좋은 정확도를 나타내는 것은 svm으로 정확도가 무려 99퍼센트에 육박한다. 와인의 경우는 random forest로써 정확도는 100퍼센트, 그리고 유방암 진단에서도 randomforest가 100퍼센트로 가장 우수한 성능을 보였다. 따라서 핸드라이팅같은 데이터 타입에서 가장 적절한 기계학습 모델은 svm모델이며 와인과 유방암 진단에서는 random forest의 모델을 활용하는 것이 위의 선택지에서 가장 적합하다. \n","\n","\n","prj limits : \n","    성능 지표는 정확도 외에 f1_score, recall이 존재하는데 이 지표들은 각 모델에서 거의 비슷한 값을 보여주고 있다. 이 지표들은 모델의 관점, 데이터의 관점에 따라 지표들이 갖는 의미를 알 수 있다. 이 지표들에 대해서 구체적인 이해가 부족하여 모델의 성능을 평가하는 기준을 고려함에 있어 한계점을 갖는다 할 수 있다. 여러 인터넷의 정보들은 단순히 지표들을 구하는 공식을 포스팅하는 수준에 그치는 경우가 많아 포괄적이고 의미론적인 내용을 접할 필요가 있다. 예를 들면 위키디피아, 논문등을 참고하여야 한다. 나는 이번 프로젝트를 통해 모델의 성능 평가 지표들을 더욱 자세히 살펴보고 모델의 적합성을 판단하는데 필요한 지식들을 탐구할 필요성을 느꼈다.\n","    \n","    \n","feelings :\n","    이전 노드에서 텐서플로우 라이브러를 활용한 가위, 바위, 보 학습과 정확도 측정은 다소 복잡한 과정을 거쳐야 했다. 처음 보는 낯선 컨볼루션함수와 하이퍼 파라미터를 유저가 설정하여야 하며 모델의 정확도와 오버피팅의 문제를 해결하기 위해 하이퍼파라미터를 조정하고 트레이닝 데이터셋과 테스트 데이터셋을 번거롭게 설정하여야 했다. 하지만 이번 노드에서 sckit-learn api가 제공하는 모듈과 함수들은 매우 간편하고 사용하는데 탁월한 기능들을 제공하였다. 훈련과 테스트 데이터를 스필릿 할 때 함수 한줄이면 자동적으로 랜덤한 분포가 이루어졌고 함수 몇줄이면 sckit-learn에서 지원하는 5가지 모델을 손쉽게 훈련하고 측정할 수 있다. \n","    하지만 나는 이러한 편의성에도 불구하고 이전 노드와 같이 여러 함수와 하이퍼파라미터를 설정하는 번거로움이 이제 막 머신러닝을 배우는 초보자의 입장에서 학습효과에 있어 효과적이라 생각한다. 모든 것이 함수 몇줄이면 작동하고 그것만을 활용한다면 그 안에 은닉된 각 기능들을 수행하는 함수와 데이터 처리가 어떻게 이루어지는지 관심을 갖지 않기 떄문이다. (이는 자동화의 역설과 크게 매치된다. ref: 유리감옥-니콜라스카)\n","\n","\n"],"execution_count":null,"outputs":[]}]}